{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on the coco dataset for region segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pycocotools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import tqdm\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import io\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import TestTubeLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "\n",
    "\n",
    "from UNeXt.archs import UNext\n",
    "from UNeXt.losses import BCEDiceLoss\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models import *\n",
    "from datasets import *\n",
    "from IcyXml import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# class CocoDataset(Dataset):\n",
    "#     def __init__(self, root_dir, ann_file, transforms=None):\n",
    "#         self.root_dir = root_dir\n",
    "#         self.transforms = transforms\n",
    "#         self.coco = pycocotools.COCO(ann_file)\n",
    "#         self.ids = list(self.coco.imgs.keys())\n",
    "#         self.cats = self.coco.loadCats(self.coco.getCatIds())\n",
    "#         self.cat_to_id = {cat['name']: cat['id'] for cat in self.cats}\n",
    "#         self.id_to_cat = {cat['id']: cat['name'] for cat in self.cats}\n",
    "#         self.cat_to_color = {cat['name']: cat['color'] for cat in self.cats}\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.ids)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_id = self.ids[idx]\n",
    "#         img_path = os.path.join(self.root_dir, self.coco.imgs[img_id]['file_name'])\n",
    "#         img = io.read_image(img_path, io.image.ImageReadMode.RGB)\n",
    "#         # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         # img = cv2.resize(img, (256, 256))\n",
    "#         img = img.astype(np.float32) / 255\n",
    "#         img = torch.from_numpy(img)\n",
    "#         if self.transforms:\n",
    "#             img = self.transforms(img)\n",
    "#         mask = self.coco.anns[self.coco.imgToAnns[img_id]]['segmentation']\n",
    "#         mask = mask.astype(np.float32)\n",
    "#         mask = torch.from_numpy(mask)\n",
    "#         mask = mask.unsqueeze(0)\n",
    "#         mask = mask.unsqueeze(0)\n",
    "#         mask = mask.float()\n",
    "#         return img, mask\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# root_dir = \"/home/mounib/cell-counting/datasets/\"\n",
    "# os.listdir(root_dir)\n",
    "# # list all json files in the root directory\n",
    "# ann_files = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith('.json')]\n",
    "# coco = COCO(ann_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# id2color = {0: np.array([255, 255, 0]),\n",
    "#             1: np.array([255, 0, 0]),\n",
    "#             2: np.array([0, 255, 230]),\n",
    "#             3: np.array([255, 0, 255]),\n",
    "#             4: np.array([218,215,215]),\n",
    "#             5: np.array([0,0,255]),\n",
    "#             6: np.array([255,253,224]),\n",
    "#             7: np.array([20,20,20]),\n",
    "#             8: np.array([255,128,0]),\n",
    "#             9: np.array([255,255,184]),\n",
    "#             10: np.array([100,100,100]),\n",
    "#             11: np.array([214,237,255])}\n",
    "# def draw_masks(img, masks):\n",
    "#     # annotations = np.zeros(img.shape, dtype=np.uint8)\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.imshow(img)\n",
    "#     # plt.imshow(annotations, alpha=0.2)\n",
    "\n",
    "#     for mask in masks:\n",
    "#         plt.imshow(mask, alpha=0.5)\n",
    "\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# cat = coco.getCatIds()\n",
    "# categories = coco.loadCats(cat)\n",
    "# nimgs = 20\n",
    "\n",
    "# for i in range(nimgs):\n",
    "#     id = list(coco.imgs.items())[i][0]\n",
    "    \n",
    "#     print(\"Image ID: \", id)\n",
    "\n",
    "#     img = cv2.imread(os.path.join(root_dir, list(coco.imgs.items())[i][1][\"file_name\"]))\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = img.astype(np.uint8)\n",
    "#     # print(img.min(), img.max())\n",
    "#     annotations = coco.loadAnns(coco.getAnnIds(imgIds=id))\n",
    "#     # print(id, annotations)\n",
    "#     # masks = np.zeros((nimgs, len(cat), img.shape[0], img.shape[1]), dtype=np.uint8)\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.imshow(img)\n",
    "#     print(list(coco.imgs.items())[i][1][\"file_name\"])\n",
    "#     for annotation in annotations:\n",
    "#         # print(annotation[\"segmentation\"])\n",
    "#         if(len(annotation[\"segmentation\"][0]) < 4):\n",
    "#             continue\n",
    "\n",
    "#         if annotation[\"category_id\"] != -1:\n",
    "#             print(categories[annotation[\"category_id\"]][\"name\"])\n",
    "#             for n, anno in enumerate(annotation[\"segmentation\"]):\n",
    "#                 # print(anno)\n",
    "#                 # if(n != 0):\n",
    "#                 #     anno = anno[2:]\n",
    "#                 poly = Polygon(np.array(anno).reshape((-1, 2)), closed=True, edgecolor=\"#000000\", facecolor=id2color[annotation[\"category_id\"]]/255, linewidth=5, alpha=0.4)\n",
    "#                 plt.gca().add_patch(poly)\n",
    "#                 # break\n",
    "#         # color = id2color[annotation[\"category_id\"]]\n",
    "#         # mask[annotation[\"category_id\"]] = np.logical_or(mask[annotation[\"category_id\"]], mask)\n",
    "#     plt.show()\n",
    "#     # masks = np.array([coco.annToMask(annotations[j]) for j in range(1, len(annotations)-1)])\n",
    "#     # draw_masks(img, masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.35s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pl.seed_everything(42)\n",
    "# root_dir=\"/home/mounib/cell-counting/datasets/\"\n",
    "root_dir = \"/data\"\n",
    "ann_files = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith('.json')]\n",
    "dataset = LungTumorDataset(root_dir, ann_files[0], None, imageSize=512)\n",
    "\n",
    "trainDataset, validDataset = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.8), int(len(dataset) * 0.2)+1])\n",
    "\n",
    "trainDataLoader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=8, pin_memory=True, prefetch_factor=2)\n",
    "validDataLoader = DataLoader(validDataset, batch_size=8, shuffle=False, num_workers=8, pin_memory=True, prefetch_factor=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model = UNext(len(dataset.cats), 3, False)\n",
    "plModel = SegModel(model, None)\n",
    "# plModel = plModel.load_from_checkpoint(\"lightning_logs/version_2/checkpoints/epoch=261-step=11265.ckpt\", backbone=model)\n",
    "plModel = plModel.load_from_checkpoint(\"lightning_logs/version_14/checkpoints/epoch=13-step=2365.ckpt\", backbone=model)\n",
    "# for module in model.children():\n",
    "#     print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:45: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v1.7. Please pass `Trainer.fit(ckpt_path=)` directly instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/trainer.py:1905: LightningDeprecationWarning: `trainer.resume_from_checkpoint` is deprecated in v1.5 and will be removed in v1.7. Specify the fit checkpoint path with `trainer.fit(ckpt_path=)` instead.\n",
      "  rank_zero_deprecation(\n",
      "Restoring states from the checkpoint path at lightning_logs/version_14/checkpoints/epoch=13-step=2365.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:250: UserWarning: You're resuming from a checkpoint that ended mid-epoch. Training will start from the beginning of the next epoch. This can cause unreliable results if further training is done, consider using an end of epoch checkpoint.\n",
      "  rank_zero_warn(\n",
      "Restored all states from the checkpoint file at lightning_logs/version_14/checkpoints/epoch=13-step=2365.ckpt\n",
      "\n",
      "  | Name | Type        | Params\n",
      "-------------------------------------\n",
      "0 | net  | UNext       | 1.5 M \n",
      "1 | loss | BCEDiceLoss | 0     \n",
      "-------------------------------------\n",
      "1.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 M     Total params\n",
      "5.888     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 102/102 [01:14<00:00,  1.37it/s, loss=0.128, v_num=15]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=400, gpus=1, resume_from_checkpoint=\"lightning_logs/version_14/checkpoints/epoch=13-step=2365.ckpt\")\n",
    "trainer.fit(plModel, trainDataLoader, validDataLoader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     img, mask = dataset[i]\n",
    "#     dataset.draw_mask(img, mask)\n",
    "\n",
    "# for i, batch in enumerate(dataLoader):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(len(dataset)):\n",
    "#     img, mask = dataset[i]\n",
    "#     print(img.shape, mask.shape)\n",
    "    # extract the contours from a mask\n",
    "def extract_contours(masks, eps=0.001):\n",
    "    \"\"\"\n",
    "    Extract the contours from a mask\n",
    "    :param masks: a list of masks one for each channel\"\"\"\n",
    "    contours = []\n",
    "    for i, mask in enumerate(masks):\n",
    "        externals, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        name = dataset.id2cat[i]\n",
    "        color = dataset.name2color[name]\n",
    "        if len(externals) > 0:\n",
    "            # print(len(externals))\n",
    "            contours += list((cv2.approxPolyDP((external).squeeze(1), eps * cv2.arcLength((external).squeeze(1), True), True).squeeze(1), name, color) for external in externals)\n",
    "    \n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 673/673 [23:07<00:00,  2.06s/it]\n"
     ]
    }
   ],
   "source": [
    "plModel.eval()\n",
    "device = plModel.device\n",
    "dataset.transforms = None\n",
    "dataset.imageSize = 2048\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(dataset))):\n",
    "        img, gtMask = dataset[i]\n",
    "        # print(img.shape)\n",
    "        out = plModel(img.unsqueeze(0).to(device))\n",
    "        out = torch.sigmoid(out)\n",
    "        out = out > 0.5\n",
    "        out = out.cpu().squeeze(0)\n",
    "\n",
    "        # print(gtMask.min(), gtMask.max())\n",
    "\n",
    "        # figure = plt.figure(figsize=(25, 10))\n",
    "        # plt.subplot(1, 2, 1)\n",
    "        # plt.title(\"Prediction\")\n",
    "        # dataset.draw_mask(img, out, gtMask)\n",
    "        # plt.subplot(1, 2, 2)\n",
    "        # plt.title(\"ground truth\")\n",
    "\n",
    "\n",
    "        masks = out.cpu().numpy().astype(np.uint8)\n",
    "        # print(masks.dtype, masks.min(), masks.max(), masks.shape)\n",
    "        contours = extract_contours(masks)\n",
    "\n",
    "\n",
    "        img_id = dataset.ids[i]\n",
    "        # img_path = os.path.join(dataset.root_dir, dataset.coco.imgs[img_id]['file_name'])\n",
    "        img_path = dataset.coco.imgs[img_id]['file_name']\n",
    "        annot_file = \".\".join(img_path.split('.')[:-1]) + \".xml\"\n",
    "        # print(img_path, annot_file)\n",
    "\n",
    "        icyFile = IcyXml(root_dir, annot_file)\n",
    "\n",
    "\n",
    "        for i, (contour, name, color) in enumerate(contours):\n",
    "            # print(name)\n",
    "            icyFile.addPolygon(contour, name, color)\n",
    "        \n",
    "        icyFile.save()\n",
    "            \n",
    "        #     # print(contour)\n",
    "        #     pp = Polygon(contour)\n",
    "        #     x, y = pp.exterior.xy\n",
    "        #     plt.figure(figsize=(5,5))\n",
    "        #     plt.plot(x, y, 'ro-')\n",
    "            \n",
    "            # plt.plot(contour[:, 0], contour[:, 1], 'ro-')\n",
    "            # plt.xlim(0, img.shape[2])\n",
    "            # plt.ylim(0, img.shape[1])\n",
    "            # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8 0 1 (12, 2048, 2048)\n"
     ]
    }
   ],
   "source": [
    "masks = out.cpu().numpy().astype(np.uint8)\n",
    "print(masks.dtype, masks.min(), masks.max(), masks.shape)\n",
    "contours = extract_contours(masks, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1621, 1981],\n",
       "        [1620, 1981],\n",
       "        [1619, 1983],\n",
       "        [1617, 1983],\n",
       "        [1612, 1980],\n",
       "        [1607, 1979],\n",
       "        [1603, 1983],\n",
       "        [1603, 1984],\n",
       "        [1599, 1987],\n",
       "        [1599, 1995],\n",
       "        [1602, 1998],\n",
       "        [1602, 1999],\n",
       "        [1606, 2004],\n",
       "        [1607, 2008],\n",
       "        [1607, 2006],\n",
       "        [1609, 2003],\n",
       "        [1610, 2004],\n",
       "        [1615, 2004],\n",
       "        [1617, 2002],\n",
       "        [1621, 2002],\n",
       "        [1621, 2000],\n",
       "        [1625, 1997],\n",
       "        [1625, 1994],\n",
       "        [1623, 1990],\n",
       "        [1623, 1983]], dtype=int32),\n",
       " 'Tumor Islet',\n",
       " array([255, 128,   0]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contours[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "color = contours[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16711935"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
