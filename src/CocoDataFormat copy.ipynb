{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on the coco dataset for region segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pycocotools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import tqdm\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import io\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import TestTubeLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "\n",
    "\n",
    "from UNeXt.archs import UNext\n",
    "from UNeXt.losses import BCEDiceLoss\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models import *\n",
    "from datasets import *\n",
    "from IcyXml import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# class CocoDataset(Dataset):\n",
    "#     def __init__(self, root_dir, ann_file, transforms=None):\n",
    "#         self.root_dir = root_dir\n",
    "#         self.transforms = transforms\n",
    "#         self.coco = pycocotools.COCO(ann_file)\n",
    "#         self.ids = list(self.coco.imgs.keys())\n",
    "#         self.cats = self.coco.loadCats(self.coco.getCatIds())\n",
    "#         self.cat_to_id = {cat['name']: cat['id'] for cat in self.cats}\n",
    "#         self.id_to_cat = {cat['id']: cat['name'] for cat in self.cats}\n",
    "#         self.cat_to_color = {cat['name']: cat['color'] for cat in self.cats}\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.ids)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_id = self.ids[idx]\n",
    "#         img_path = os.path.join(self.root_dir, self.coco.imgs[img_id]['file_name'])\n",
    "#         img = io.read_image(img_path, io.image.ImageReadMode.RGB)\n",
    "#         # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#         # img = cv2.resize(img, (256, 256))\n",
    "#         img = img.astype(np.float32) / 255\n",
    "#         img = torch.from_numpy(img)\n",
    "#         if self.transforms:\n",
    "#             img = self.transforms(img)\n",
    "#         mask = self.coco.anns[self.coco.imgToAnns[img_id]]['segmentation']\n",
    "#         mask = mask.astype(np.float32)\n",
    "#         mask = torch.from_numpy(mask)\n",
    "#         mask = mask.unsqueeze(0)\n",
    "#         mask = mask.unsqueeze(0)\n",
    "#         mask = mask.float()\n",
    "#         return img, mask\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# root_dir = \"/home/mounib/cell-counting/datasets/\"\n",
    "# os.listdir(root_dir)\n",
    "# # list all json files in the root directory\n",
    "# ann_files = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith('.json')]\n",
    "# coco = COCO(ann_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# id2color = {0: np.array([255, 255, 0]),\n",
    "#             1: np.array([255, 0, 0]),\n",
    "#             2: np.array([0, 255, 230]),\n",
    "#             3: np.array([255, 0, 255]),\n",
    "#             4: np.array([218,215,215]),\n",
    "#             5: np.array([0,0,255]),\n",
    "#             6: np.array([255,253,224]),\n",
    "#             7: np.array([20,20,20]),\n",
    "#             8: np.array([255,128,0]),\n",
    "#             9: np.array([255,255,184]),\n",
    "#             10: np.array([100,100,100]),\n",
    "#             11: np.array([214,237,255])}\n",
    "# def draw_masks(img, masks):\n",
    "#     # annotations = np.zeros(img.shape, dtype=np.uint8)\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.imshow(img)\n",
    "#     # plt.imshow(annotations, alpha=0.2)\n",
    "\n",
    "#     for mask in masks:\n",
    "#         plt.imshow(mask, alpha=0.5)\n",
    "\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# cat = coco.getCatIds()\n",
    "# categories = coco.loadCats(cat)\n",
    "# nimgs = 20\n",
    "\n",
    "# for i in range(nimgs):\n",
    "#     id = list(coco.imgs.items())[i][0]\n",
    "    \n",
    "#     print(\"Image ID: \", id)\n",
    "\n",
    "#     img = cv2.imread(os.path.join(root_dir, list(coco.imgs.items())[i][1][\"file_name\"]))\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = img.astype(np.uint8)\n",
    "#     # print(img.min(), img.max())\n",
    "#     annotations = coco.loadAnns(coco.getAnnIds(imgIds=id))\n",
    "#     # print(id, annotations)\n",
    "#     # masks = np.zeros((nimgs, len(cat), img.shape[0], img.shape[1]), dtype=np.uint8)\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.imshow(img)\n",
    "#     print(list(coco.imgs.items())[i][1][\"file_name\"])\n",
    "#     for annotation in annotations:\n",
    "#         # print(annotation[\"segmentation\"])\n",
    "#         if(len(annotation[\"segmentation\"][0]) < 4):\n",
    "#             continue\n",
    "\n",
    "#         if annotation[\"category_id\"] != -1:\n",
    "#             print(categories[annotation[\"category_id\"]][\"name\"])\n",
    "#             for n, anno in enumerate(annotation[\"segmentation\"]):\n",
    "#                 # print(anno)\n",
    "#                 # if(n != 0):\n",
    "#                 #     anno = anno[2:]\n",
    "#                 poly = Polygon(np.array(anno).reshape((-1, 2)), closed=True, edgecolor=\"#000000\", facecolor=id2color[annotation[\"category_id\"]]/255, linewidth=5, alpha=0.4)\n",
    "#                 plt.gca().add_patch(poly)\n",
    "#                 # break\n",
    "#         # color = id2color[annotation[\"category_id\"]]\n",
    "#         # mask[annotation[\"category_id\"]] = np.logical_or(mask[annotation[\"category_id\"]], mask)\n",
    "#     plt.show()\n",
    "#     # masks = np.array([coco.annToMask(annotations[j]) for j in range(1, len(annotations)-1)])\n",
    "#     # draw_masks(img, masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pl.seed_everything(42)\n",
    "# root_dir=\"/home/mounib/cell-counting/datasets/\"\n",
    "# root_dir = \"/Datasets/\"\n",
    "root_dir = \"/data\"\n",
    "ann_files = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith('.json')]\n",
    "dataset = LungTumorDataset(root_dir, ann_files[1], None, imageSize=512)\n",
    "\n",
    "trainDataset, validDataset = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.8), int(len(dataset) * 0.2)+1])\n",
    "\n",
    "trainDataLoader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=8, pin_memory=True, prefetch_factor=2)\n",
    "validDataLoader = DataLoader(validDataset, batch_size=8, shuffle=False, num_workers=8, pin_memory=True, prefetch_factor=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model = UNext(len(dataset.cats), 3, False)\n",
    "plModel = SegModel(model, None)\n",
    "# plModel = plModel.load_from_checkpoint(\"lightning_logs/version_2/checkpoints/epoch=261-step=11265.ckpt\", backbone=model)\n",
    "plModel = plModel.load_from_checkpoint(\"lightning_logs/version_15/checkpoints/epoch=399-step=35175.ckpt\", backbone=model)\n",
    "# for module in model.children():\n",
    "#     print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(max_epochs=400, gpus=1, resume_from_checkpoint=\"lightning_logs/version_14/checkpoints/epoch=13-step=2365.ckpt\")\n",
    "# trainer.fit(plModel, trainDataLoader, validDataLoader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     img, mask = dataset[i]\n",
    "#     dataset.draw_mask(img, mask)\n",
    "\n",
    "# for i, batch in enumerate(dataLoader):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(len(dataset)):\n",
    "#     img, mask = dataset[i]\n",
    "#     print(img.shape, mask.shape)\n",
    "    # extract the contours from a mask\n",
    "def extract_contours(masks, eps=0.002):\n",
    "    \"\"\"\n",
    "    Extract the contours from a mask\n",
    "    :param masks: a list of masks one for each channel\"\"\"\n",
    "    contours = []\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(20,20))\n",
    "    for i, mask in enumerate(masks):\n",
    "\n",
    "\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "\n",
    "        externals, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        name = dataset.id2cat[i]\n",
    "        color = dataset.name2color[name]\n",
    "        if len(externals) > 0:\n",
    "            # print(len(externals))\n",
    "            contours += list((cv2.approxPolyDP((external).squeeze(1), eps * cv2.arcLength((external).squeeze(1), True), True).squeeze(1), name, color) for external in externals)\n",
    "    \n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 342/342 [01:21<00:00,  4.17it/s]\n"
     ]
    }
   ],
   "source": [
    "plModel.eval()\n",
    "device = plModel.device\n",
    "dataset.transforms = None\n",
    "dataset.imageSize = 512\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i in tqdm.tqdm(range(len(dataset))):\n",
    "        img, gtMask = dataset[i]\n",
    "        # print(img.shape)\n",
    "        out = plModel(img.unsqueeze(0).to(device))\n",
    "        out = torch.sigmoid(out)\n",
    "        out = out > 0.5\n",
    "        out = out.cpu().squeeze(0)\n",
    "\n",
    "        # print(gtMask.min(), gtMask.max())\n",
    "\n",
    "        # figure = plt.figure(figsize=(25, 10))\n",
    "        # plt.subplot(1, 2, 1)\n",
    "        # plt.title(\"Prediction\")\n",
    "        # dataset.draw_mask(img, out, gtMask)\n",
    "        # plt.subplot(1, 2, 2)\n",
    "        # plt.title(\"ground truth\")\n",
    "\n",
    "\n",
    "        masks = out.cpu().numpy().astype(np.uint8)\n",
    "        # print(masks.dtype, masks.min(), masks.max(), masks.shape)\n",
    "        contours = extract_contours(masks)\n",
    "\n",
    "\n",
    "        img_id = dataset.ids[i]\n",
    "        # img_path = os.path.join(dataset.root_dir, dataset.coco.imgs[img_id]['file_name'])\n",
    "        img_path = dataset.coco.imgs[img_id]['file_name']\n",
    "        annot_file = \".\".join(img_path.split('.')[:-1]) + \".xml\"\n",
    "        # print(img_path, annot_file)\n",
    "\n",
    "        icyFile = IcyXml(root_dir, annot_file)\n",
    "\n",
    "\n",
    "        for i, (contour, name, color) in enumerate(contours):\n",
    "            # print(name)\n",
    "            icyFile.addPolygon(contour, name, color)\n",
    "        \n",
    "        icyFile.save()\n",
    "            \n",
    "        #     # print(contour)\n",
    "        #     pp = Polygon(contour)\n",
    "        #     x, y = pp.exterior.xy\n",
    "        #     plt.figure(figsize=(5,5))\n",
    "        #     plt.plot(x, y, 'ro-')\n",
    "            \n",
    "            # plt.plot(contour[:, 0], contour[:, 1], 'ro-')\n",
    "            # plt.xlim(0, img.shape[2])\n",
    "            # plt.ylim(0, img.shape[1])\n",
    "            # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8 0 1 (12, 512, 512)\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "masks = out.cpu().numpy().astype(np.uint8)\n",
    "print(masks.dtype, masks.min(), masks.max(), masks.shape)\n",
    "contours = extract_contours(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
